{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f785df67-ce40-44b5-8375-9af6d3c5420a",
   "metadata": {},
   "source": [
    "# Local Visual QA with LLaMA 3.2 Vision\n",
    "## ABB #1 - Session 3\n",
    "\n",
    "Code authored by: Shaw Talebi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab25a6-d20f-450e-9981-d43bd29a3181",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc60723-d912-40ed-9b22-260b88d2182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawhin/Documents/_code/_stv/ABB/AI-Builders-Bootcamp-1/session-3/s3-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import gradio as gr\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe3d9d-0759-4832-820f-0d555357bc1f",
   "metadata": {},
   "source": [
    "### basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72e1dd0-b473-49fe-a1eb-0f3fa8a98340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull model\n",
    "ollama.pull('llama3.2-vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fd54ff-0e11-4a92-aa29-3735be934fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The abstract of the paper states that it proposes a new system for translating text from German to English. The system, known as BLEU (Bilingual Evaluation Understudy), uses deep learning techniques to generate more accurate and natural-sounding translations than existing methods.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Parallelization**: The model achieves significant speedup by dividing the translation task into smaller sub-tasks that can be processed in parallel.\n",
      "* **Improved Accuracy**: The system produces more accurate and natural-sounding translations than existing methods.\n",
      "* **Efficient Training**: The model is trained using a combination of supervised and unsupervised learning techniques, which allows it to learn from large amounts of data quickly and efficiently.\n",
      "\n",
      "**Impact:**\n",
      "\n",
      "The paper presents a new approach to machine translation that has the potential to significantly improve the accuracy and efficiency of language translation systems. By leveraging deep learning techniques and parallelization, the system can handle complex tasks such as translating text from one language to another while maintaining the nuances and context of the original text."
     ]
    }
   ],
   "source": [
    "# interact with model (locally)\n",
    "stream = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is this paper about?',\n",
    "        'images': ['papers/attention-is-all-you-need.png']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402a518-7d2d-4158-93c3-dcddbbf5ce1e",
   "metadata": {},
   "source": [
    "### gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3ee81f-4a84-4fca-a2a0-01a8e7783b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with the Ollama model\n",
    "def stream_chat(message, history):\n",
    "    \"\"\"\n",
    "    Streams the response from the Ollama model and sends it to the Gradio UI.\n",
    "    \n",
    "    Args:\n",
    "        message (str): The user input message.\n",
    "        history (list): A list of previous conversation messages.\n",
    "        \n",
    "    Yields:\n",
    "        str: The chatbot's response chunk by chunk.\n",
    "    \"\"\"\n",
    "    # Append the user message to the conversation history\n",
    "    history.append({\"role\": \"user\", \"content\": message[\"text\"], \"images\":message[\"files\"]})\n",
    "    \n",
    "    # Initialize streaming from Ollama\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.2-vision',\n",
    "        messages=history,  # Full chat history including the current user message\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    response_text = \"\"\n",
    "    for chunk in stream:\n",
    "        content = chunk['message']['content']\n",
    "        response_text += content\n",
    "        yield response_text  # Send the response incrementally to the UI\n",
    "\n",
    "    # Append the assistant's full response to the history\n",
    "    history.append({\"role\": \"assistant\", \"content\": response_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2072e9ee-c43b-4702-a79e-29e7ac8f3a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Gradio ChatInterface\n",
    "gr.ChatInterface(\n",
    "    fn=stream_chat,  # The function handling the chat\n",
    "    type=\"messages\",  # Using \"messages\" to enable chat-style conversation\n",
    "    examples=[{\"text\": \"What is this paper about?\", \"files\": ['papers/attention-is-all-you-need.png']}],  # Example inputs\n",
    "    multimodal=True,\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e4b9a-ebeb-458e-bce5-b4812937febb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
